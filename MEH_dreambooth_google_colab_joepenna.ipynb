{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab5eS5Zu2538"
      },
      "source": [
        "## Dreambooth\n",
        "#### Colab implementation by David Bielejeski. Latest information on: https://github.com/JoePenna/Dreambooth-Stable-Diffusion\n",
        "##### Before starting, make sure you have the appropriate Accelerator and GPU Type selected from the Runtime menu `Runtime > Change runtime type`.  A minimum of 24GB of VRAM is required so you should select the A100 GPU (40GB). Both the T4 and V100 have less than 20GB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "TM2GMddrCSfo",
        "outputId": "df9e54db-3cd4-463a-ed1f-a689e75c4a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA A100-SXM4-40GB, 40960 MiB, 40513 MiB\n",
            "\n",
            "\u001b[92mIf the available VRAM is equal or more than 24GB, then you are good to go.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title Check GPU and VRAM available. (Optional)\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "print(\"\\n\\033[92mIf the available VRAM is equal or more than 24GB, then you are good to go.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "KndPiTJjCSfr",
        "outputId": "1dcb67ea-1503-465f-fc88-4f42b98c66cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Dreambooth-Stable-Diffusion' already exists and is not an empty directory.\n",
            "/content/Dreambooth-Stable-Diffusion\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Clone & Download The Repo\n",
        "!git clone https://github.com/JoePenna/Dreambooth-Stable-Diffusion\n",
        "%cd Dreambooth-Stable-Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeTrc2vOeiNh",
        "cellView": "form",
        "outputId": "81525f73-76e5-4cd1-ac3f-07295e739c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)\n",
            "Requirement already satisfied: pytorch-lightning==1.7.6 in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (1.23.1)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (6.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (2023.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (2.12.3)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (0.11.1)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (0.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.7.6) (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (3.8.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->pytorch-lightning==1.7.6) (0.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.6) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.6) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.6) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.6) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.*->pytorch-lightning==1.7.6) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.*->pytorch-lightning==1.7.6) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.*->pytorch-lightning==1.7.6) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.7.6) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.*->pytorch-lightning==1.7.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->pytorch-lightning==1.7.6) (3.2.2)\n",
            "Requirement already satisfied: csv-logger in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torchmetrics==0.11.1 in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.1) (1.23.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.1) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.1) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics==0.11.1) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics==0.11.1) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==0.11.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==0.11.1) (1.3.0)\n",
            "Requirement already satisfied: torch-fidelity==0.3.0 in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (1.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (1.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity==0.3.0) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity==0.3.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torch-fidelity==0.3.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torch-fidelity==0.3.0) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->torch-fidelity==0.3.0) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-fidelity==0.3.0) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->torch-fidelity==0.3.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->torch-fidelity==0.3.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->torch-fidelity==0.3.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->torch-fidelity==0.3.0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-fidelity==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: albumentations==1.1.0 in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.1.0) (1.23.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==1.1.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.1.0) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.1.0) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.1.0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.1.0) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.1.0) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.1.0) (4.6.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.1.0) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (3.1.0)\n",
            "Requirement already satisfied: opencv-python==4.7.0.72 in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.7.0.72) (1.23.1)\n",
            "Requirement already satisfied: pudb==2019.2 in /usr/local/lib/python3.10/dist-packages (2019.2)\n",
            "Requirement already satisfied: urwid>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from pudb==2019.2) (2.1.2)\n",
            "Requirement already satisfied: pygments>=1.0 in /usr/local/lib/python3.10/dist-packages (from pudb==2019.2) (2.14.0)\n",
            "Requirement already satisfied: omegaconf==2.1.1 in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.1) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.1) (6.0)\n",
            "Requirement already satisfied: pillow==9.4.0 in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: einops==0.4.1 in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: transformers==4.25.1 in /usr/local/lib/python3.10/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (1.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (3.4)\n",
            "Requirement already satisfied: kornia==0.6.7 in /usr/local/lib/python3.10/dist-packages (0.6.7)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from kornia==0.6.7) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia==0.6.7) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->kornia==0.6.7) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->kornia==0.6.7) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->kornia==0.6.7) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->kornia==0.6.7) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->kornia==0.6.7) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->kornia==0.6.7) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->kornia==0.6.7) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->kornia==0.6.7) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->kornia==0.6.7) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->kornia==0.6.7) (1.3.0)\n",
            "Requirement already satisfied: diffusers[training]==0.3.0 in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (6.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (0.16.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (1.23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (2.27.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (9.4.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (0.20.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (2.13.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (2.12.3)\n",
            "Requirement already satisfied: modelcards in /usr/local/lib/python3.10/dist-packages (from diffusers[training]==0.3.0) (0.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->diffusers[training]==0.3.0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->diffusers[training]==0.3.0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->diffusers[training]==0.3.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->diffusers[training]==0.3.0) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->diffusers[training]==0.3.0) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[training]==0.3.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[training]==0.3.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[training]==0.3.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[training]==0.3.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->diffusers[training]==0.3.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->diffusers[training]==0.3.0) (16.0.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->diffusers[training]==0.3.0) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->diffusers[training]==0.3.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->diffusers[training]==0.3.0) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->diffusers[training]==0.3.0) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->diffusers[training]==0.3.0) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->diffusers[training]==0.3.0) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->diffusers[training]==0.3.0) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[training]==0.3.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[training]==0.3.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[training]==0.3.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers[training]==0.3.0) (3.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers[training]==0.3.0) (3.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->diffusers[training]==0.3.0) (0.40.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->diffusers[training]==0.3.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->diffusers[training]==0.3.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->diffusers[training]==0.3.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->diffusers[training]==0.3.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->diffusers[training]==0.3.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->diffusers[training]==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.3.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.3.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.3.0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->diffusers[training]==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->diffusers[training]==0.3.0) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->diffusers[training]==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->diffusers[training]==0.3.0) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->diffusers[training]==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.3.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->diffusers[training]==0.3.0) (3.2.2)\n",
            "Requirement already satisfied: captionizer==1.0.1 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Obtaining taming-transformers from git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
            "  Updating ./src/taming-transformers clone (to revision master)\n",
            "  Running command git fetch -q --tags\n",
            "  Running command git reset --hard -q 3ba01b241669f5ade541ce990f7650a3b8f65318\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (1.23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->taming-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->taming-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->taming-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->taming-transformers) (1.3.0)\n",
            "Installing collected packages: taming-transformers\n",
            "  Attempting uninstall: taming-transformers\n",
            "    Found existing installation: taming-transformers 0.0.1\n",
            "    Uninstalling taming-transformers-0.0.1:\n",
            "      Successfully uninstalled taming-transformers-0.0.1\n",
            "  Running setup.py develop for taming-transformers\n",
            "Successfully installed taming-transformers-0.0.1\n",
            "Obtaining clip from git+https://github.com/openai/CLIP.git@main#egg=clip\n",
            "  Updating ./src/clip clone (to revision main)\n",
            "  Running command git fetch -q --tags\n",
            "  Running command git reset --hard -q a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip) (0.15.2+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip) (0.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip) (1.23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip) (1.3.0)\n",
            "Installing collected packages: clip\n",
            "  Attempting uninstall: clip\n",
            "    Found existing installation: clip 1.0\n",
            "    Uninstalling clip-1.0:\n",
            "      Successfully uninstalled clip-1.0\n",
            "  Running setup.py develop for clip\n",
            "Successfully installed clip-1.0\n",
            "Obtaining file:///content/Dreambooth-Stable-Diffusion\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from dreambooth-stable-diffusion==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dreambooth-stable-diffusion==1.0.0) (1.23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dreambooth-stable-diffusion==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->dreambooth-stable-diffusion==1.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->dreambooth-stable-diffusion==1.0.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->dreambooth-stable-diffusion==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->dreambooth-stable-diffusion==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->dreambooth-stable-diffusion==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->dreambooth-stable-diffusion==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->dreambooth-stable-diffusion==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->dreambooth-stable-diffusion==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->dreambooth-stable-diffusion==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->dreambooth-stable-diffusion==1.0.0) (1.3.0)\n",
            "Installing collected packages: dreambooth-stable-diffusion\n",
            "  Attempting uninstall: dreambooth-stable-diffusion\n",
            "    Found existing installation: dreambooth-stable-diffusion 1.0.0\n",
            "    Uninstalling dreambooth-stable-diffusion-1.0.0:\n",
            "      Successfully uninstalled dreambooth-stable-diffusion-1.0.0\n",
            "  Running setup.py develop for dreambooth-stable-diffusion\n",
            "Successfully installed dreambooth-stable-diffusion-1.0.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (3.1.31)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython) (4.0.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Build The Environment\n",
        "#@markdown You might get warnings about restarting the runtime. Do this from the Runtime menu and after restarting, resume from Cell.\n",
        "!pip install numpy==1.23.1\n",
        "!pip install pytorch-lightning==1.7.6\n",
        "!pip install csv-logger\n",
        "!pip install torchmetrics==0.11.1\n",
        "!pip install torch-fidelity==0.3.0\n",
        "!pip install albumentations==1.1.0\n",
        "!pip install opencv-python==4.7.0.72\n",
        "!pip install pudb==2019.2\n",
        "!pip install omegaconf==2.1.1\n",
        "!pip install pillow==9.4.0\n",
        "!pip install einops==0.4.1\n",
        "!pip install transformers==4.25.1\n",
        "!pip install kornia==0.6.7\n",
        "!pip install diffusers[training]==0.3.0\n",
        "!pip install captionizer==1.0.1\n",
        "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -e .\n",
        "!pip install huggingface_hub\n",
        "!pip install gitpython\n",
        "\n",
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "Afx2ERKbCSfs",
        "outputId": "4d590a5a-19f7-4ed9-b83c-faa4ddc3c1ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dreambooth-Stable-Diffusion\n"
          ]
        }
      ],
      "source": [
        "#@title 3. Just to ensure you are in the right directory.\n",
        "%cd Dreambooth-Stable-Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O15vMMhCevib",
        "cellView": "form",
        "outputId": "99458a7f-ae24-482c-d1bc-f4e0108536a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79,
          "referenced_widgets": [
            "beb3f7467563465eac17ef6075a82b5f",
            "a01ab2b4cbf048f080ba1482bfa43e06",
            "63d546ac170948e28540fd817072367f",
            "666b564159044c1daaaed344be553eea",
            "8e4cf82a20bc408a9e616cdb087fba4f",
            "553d987bcdcb4111b54caa96120f9dec",
            "fb1a9b57768d4f6baa39dc99038c4d93",
            "59ffa4201214488c9b9e4fd8890f03ea",
            "68e3031674c94b18b59291b3e666687b",
            "0b812557959d441ca6dda58a08eaa3f1",
            "1706ffc38ec248d89fbaed5778b634d2"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " model.ckpt successfully downloaded\n"
          ]
        }
      ],
      "source": [
        "#@title 4. Download the 1.5 SD model with the improved VAE\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "downloaded_model_path = hf_hub_download(\n",
        " repo_id=\"panopstor/EveryDream\",\n",
        " filename=\"sd_v1-5_vae.ckpt\"\n",
        ")\n",
        "\n",
        "# Move the sd_v1-5_vae.ckpt to the root of this directory as \"model.ckpt\"\n",
        "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
        "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
        "clear_output()\n",
        "print(\" model.ckpt successfully downloaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N96aedTtfBjO",
        "cellView": "form",
        "outputId": "74a8bc0c-f3d3-48dd-b706-2652cd48ca5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[92mRegularization Images downloaded.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title 5. Download Regularization Images\n",
        "#@markdown Weve created the following image sets\n",
        "#@markdown - `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
        "#@markdown - `man_unsplash` - pictures from various photographers\n",
        "#@markdown - `person_ddim`\n",
        "#@markdown - `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "#@markdown - `artstyle` - provided by Hackmans - ddim @ 50 steps, CFG 10.0 <br />\n",
        "\n",
        "dataset=\"woman_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"artstyle\"]\n",
        "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
        "\n",
        "!mkdir -p regularization_images/{dataset}\n",
        "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}\n",
        "\n",
        "# remove temp folder now it is empty.\n",
        "!rm -rf Stable-Diffusion-Regularization-Images-{dataset}\n",
        "\n",
        "clear_output()\n",
        "print(\" \\033[92mRegularization Images downloaded.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A7hmdOdOfGzs",
        "cellView": "form",
        "outputId": "f3c7055d-2e59-4a0e-ef38-a6f5376525a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[92m18 training images found.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title 6. Training Images\n",
        "#@markdown ## Upload your training images\n",
        "#@markdown WARNING: Be sure to upload an even amount of images, otherwise the training inexplicably stops at 1500 steps. <br />\n",
        "#@markdown - 2-3 full body\n",
        "#@markdown - 3-5 upper body\n",
        "#@markdown - 5-12 close-up on face  <br /> <br />\n",
        "#@markdown The images should be as close as possible to the kind of images youre trying to make (most of the time, that means no selfies).<br /><br />\n",
        "#@markdown If you get an error during uploading, just manually drag your training images into the training_images folder.\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create the directory\n",
        "!rm -rf training_images\n",
        "!mkdir -p training_images\n",
        "\n",
        "# Upload the files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        " updated_file_name = filename.replace(\" \", \"_\")\n",
        " !mv \"{filename}\" \"training_images/{updated_file_name}\"\n",
        " clear_output()\n",
        "\n",
        "# Tell the user what is going on\n",
        "training_images_file_paths = !find training_images/*\n",
        "if len(training_images_file_paths) == 0:\n",
        " print(\" \\033[91mno training images found. Please upload images to training_images.\\033[0m\")\n",
        "else:\n",
        " print(\" \\033[92m\" + str(len(training_images_file_paths)) + \" training images found.\\033[0m\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m2o_fFFvfxHi",
        "outputId": "2622c283-a656-4699-c8d8-4312313af67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-06 21:33:31.548286: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-07-06 21:33:31.602195: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-06 21:33:32.522239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "Moving 0 files to the new cache system\n",
            "0it [00:00, ?it/s]\n",
            "Global seed set to 23\n",
            "gpu_vram: 39.56 GB\n",
            "Loading model from model.ckpt\n",
            "\n",
            "\n",
            "---------------------------\n",
            "<THIS IS LIKELY NOT AN ERROR>\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Downloading ()olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 11.2MB/s]\n",
            "Downloading ()olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 2.18MB/s]\n",
            "Downloading ()cial_tokens_map.json: 100% 389/389 [00:00<00:00, 2.80MB/s]\n",
            "Downloading ()okenizer_config.json: 100% 905/905 [00:00<00:00, 6.31MB/s]\n",
            "Downloading ()lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 23.2MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:03<00:00, 442MB/s]\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'logit_scale', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'text_projection.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Restored from model.ckpt with 12 missing and 0 unexpected keys\n",
            "Missing Keys: ['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2']\n",
            "</THIS IS LIKELY NOT AN ERROR>\n",
            "---------------------------\n",
            "\n",
            "\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "LatentDiffusion: Also optimizing conditioner params!\n",
            "Project config\n",
            "model:\n",
            "  base_learning_rate: 1.0e-06\n",
            "  target: ldm.models.diffusion.ddpm.LatentDiffusion\n",
            "  params:\n",
            "    reg_weight: 1.0\n",
            "    linear_start: 0.00085\n",
            "    linear_end: 0.012\n",
            "    num_timesteps_cond: 1\n",
            "    log_every_t: 200\n",
            "    timesteps: 1000\n",
            "    first_stage_key: image\n",
            "    cond_stage_key: caption\n",
            "    image_size: 64\n",
            "    channels: 4\n",
            "    cond_stage_trainable: true\n",
            "    conditioning_key: crossattn\n",
            "    monitor: val/loss_simple_ema\n",
            "    scale_factor: 0.18215\n",
            "    use_ema: false\n",
            "    embedding_reg_weight: 0.0\n",
            "    unfreeze_model: true\n",
            "    model_lr: 1.0e-06\n",
            "    personalization_config:\n",
            "      target: ldm.modules.embedding_manager.EmbeddingManager\n",
            "      params:\n",
            "        placeholder_strings:\n",
            "        - '*'\n",
            "        initializer_words:\n",
            "        - sculpture\n",
            "        per_image_tokens: false\n",
            "        num_vectors_per_token: 1\n",
            "        progressive_words: false\n",
            "    unet_config:\n",
            "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
            "      params:\n",
            "        image_size: 32\n",
            "        in_channels: 4\n",
            "        out_channels: 4\n",
            "        model_channels: 320\n",
            "        attention_resolutions:\n",
            "        - 4\n",
            "        - 2\n",
            "        - 1\n",
            "        num_res_blocks: 2\n",
            "        channel_mult:\n",
            "        - 1\n",
            "        - 2\n",
            "        - 4\n",
            "        - 4\n",
            "        num_heads: 8\n",
            "        use_spatial_transformer: true\n",
            "        transformer_depth: 1\n",
            "        context_dim: 768\n",
            "        use_checkpoint: true\n",
            "        legacy: false\n",
            "    first_stage_config:\n",
            "      target: ldm.models.autoencoder.AutoencoderKL\n",
            "      params:\n",
            "        embed_dim: 4\n",
            "        monitor: val/rec_loss\n",
            "        ddconfig:\n",
            "          double_z: true\n",
            "          z_channels: 4\n",
            "          resolution: 512\n",
            "          in_channels: 3\n",
            "          out_ch: 3\n",
            "          ch: 128\n",
            "          ch_mult:\n",
            "          - 1\n",
            "          - 2\n",
            "          - 4\n",
            "          - 4\n",
            "          num_res_blocks: 2\n",
            "          attn_resolutions: []\n",
            "          dropout: 0.0\n",
            "        lossconfig:\n",
            "          target: torch.nn.Identity\n",
            "    cond_stage_config:\n",
            "      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder\n",
            "    ckpt_path: model.ckpt\n",
            "data:\n",
            "  target: main.DataModuleFromConfig\n",
            "  params:\n",
            "    batch_size: 1\n",
            "    num_workers: 1\n",
            "    wrap: false\n",
            "    train:\n",
            "      target: ldm.data.personalized.PersonalizedBase\n",
            "      params:\n",
            "        size: 512\n",
            "        set: train\n",
            "        per_image_tokens: false\n",
            "        repeats: 100\n",
            "        coarse_class_text: woman\n",
            "        data_root: /content/Dreambooth-Stable-Diffusion/training_images\n",
            "        placeholder_token: mehseawa\n",
            "        token_only: false\n",
            "        flip_p: 0.0\n",
            "    reg:\n",
            "      target: ldm.data.personalized.PersonalizedBase\n",
            "      params:\n",
            "        size: 512\n",
            "        set: train\n",
            "        reg: true\n",
            "        per_image_tokens: false\n",
            "        repeats: 10\n",
            "        data_root: /content/Dreambooth-Stable-Diffusion/regularization_images/woman_ddim\n",
            "        coarse_class_text: woman\n",
            "        placeholder_token: mehseawa\n",
            "    validation:\n",
            "      target: ldm.data.personalized.PersonalizedBase\n",
            "      params:\n",
            "        size: 512\n",
            "        set: val\n",
            "        per_image_tokens: false\n",
            "        repeats: 10\n",
            "        coarse_class_text: woman\n",
            "        placeholder_token: mehseawa\n",
            "        data_root: /content/Dreambooth-Stable-Diffusion/training_images\n",
            "lightning:\n",
            "  modelcheckpoint:\n",
            "    params:\n",
            "      every_n_train_steps: 500\n",
            "  callbacks:\n",
            "    image_logger:\n",
            "      target: dreambooth_helpers.callback_helpers.ImageLogger\n",
            "      params:\n",
            "        batch_frequency: 500\n",
            "        max_images: 8\n",
            "        increase_log_steps: false\n",
            "  trainer:\n",
            "    accelerator: gpu\n",
            "    devices: 0,\n",
            "    benchmark: true\n",
            "    accumulate_grad_batches: 1\n",
            "    max_steps: 2000\n",
            "\n",
            "Lightning config\n",
            "modelcheckpoint:\n",
            "  params:\n",
            "    every_n_train_steps: 500\n",
            "callbacks:\n",
            "  image_logger:\n",
            "    target: dreambooth_helpers.callback_helpers.ImageLogger\n",
            "    params:\n",
            "      batch_frequency: 500\n",
            "      max_images: 8\n",
            "      increase_log_steps: false\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 0,\n",
            "  benchmark: true\n",
            "  accumulate_grad_batches: 1\n",
            "  max_steps: 2000\n",
            "\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | model             | DiffusionWrapper   | 859 M \n",
            "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
            "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
            "---------------------------------------------------------\n",
            "982 M     Trainable params\n",
            "83.7 M    Non-trainable params\n",
            "1.1 B     Total params\n",
            "4,264.941 Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/1818 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:98: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:231: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
            "  warning_cache.warn(\n",
            "Epoch 0:  26% 480/1818 [13:07<36:36,  1.64s/it, loss=0.307, v_num=0, train/loss_simple_step=0.252, train/loss_vlb_step=0.000917, train/loss_step=0.252, global_step=479.0]   Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:10,  4.77it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.55it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.87it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:07,  6.01it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:07,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:07,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:06,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:06,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:06,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:05,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:05,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:05,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:05,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:04,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:04,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:04,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:04,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:03,  6.31it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:03,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:03,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.34it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.34it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:03,  6.34it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:04<00:03,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:01,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:06<00:01,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:06<00:01,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:01,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:00,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:07<00:00,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:07<00:00,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:07<00:00,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:07<00:00,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.28it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  6.25it/s]\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:01<01:00,  1.23s/it]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:29,  1.62it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:19,  2.40it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:01<00:14,  3.10it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:01<00:12,  3.71it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:02<00:10,  4.20it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:02<00:09,  4.58it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:02<00:08,  4.87it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:02<00:08,  5.09it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:02<00:07,  5.24it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:03<00:07,  5.36it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:03<00:06,  5.45it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:03<00:06,  5.51it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:03<00:06,  5.55it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:03<00:06,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:03<00:06,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:04<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:04<00:05,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:04<00:05,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:04<00:05,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:04<00:05,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:04<00:04,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:05<00:04,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:05<00:04,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:05<00:04,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:05<00:04,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:05<00:04,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:06<00:03,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:06<00:03,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:06<00:03,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:06<00:03,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:06<00:03,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:06<00:03,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:07<00:02,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:07<00:02,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:07<00:02,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:07<00:02,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:07<00:02,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:07<00:01,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:08<00:01,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:08<00:01,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:08<00:01,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:08<00:01,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:08<00:01,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:09<00:00,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:09<00:00,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:09<00:00,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:09<00:00,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:09<00:00,  5.60it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:09<00:00,  5.03it/s]\n",
            "Epoch 0:  54% 980/1818 [26:52<22:58,  1.65s/it, loss=0.25, v_num=0, train/loss_simple_step=0.690, train/loss_vlb_step=0.0184, train/loss_step=0.690, global_step=979.0]pop from empty list\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:07,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:07,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:07,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:07,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:07,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:06,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:06,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:06,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  6.01it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.07it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:05,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:05,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:05,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  6.09it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:04,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:04,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:04,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  6.09it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:03,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:03,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:03,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:02,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:02,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:05<00:02,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:01,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:06<00:01,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:06<00:01,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:01,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:00,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:07<00:00,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:07<00:00,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:07<00:00,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:07<00:00,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.15it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  6.15it/s]\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:08,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:07,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:06,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:05,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:05,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:04,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:03,  5.47it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.51it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.55it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:02,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:01,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:08<00:00,  5.60it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  5.60it/s]\n",
            "Epoch 0:  81% 1480/1818 [40:36<09:16,  1.65s/it, loss=0.334, v_num=0, train/loss_simple_step=0.100, train/loss_vlb_step=0.000342, train/loss_step=0.100, global_step=1479.0]pop from empty list\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:07,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:07,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:07,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:07,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:07,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:06,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:06,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:06,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:06,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.09it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:05,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:05,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:05,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:04,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.13it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:04,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:04,  6.09it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:03,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:03,  6.09it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:03,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:02,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:02,  6.07it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:05<00:02,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  6.09it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  6.11it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:01,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:06<00:01,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:06<00:01,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:00,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:07<00:00,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:07<00:00,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:07<00:00,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:07<00:00,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.19it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  6.14it/s]\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:08,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:06,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:05,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:04,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:04,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:05<00:03,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:03,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:02,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:01,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:08<00:00,  5.56it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  5.59it/s]\n",
            "Epoch 0:  99% 1800/1818 [49:31<00:29,  1.65s/it, loss=0.252, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.00041, train/loss_step=0.124, global_step=1799.0]   \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 1818/1818 [49:39<00:00,  1.64s/it, loss=0.252, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.00041, train/loss_step=0.124, global_step=1799.0]\n",
            "                                                            \u001b[A/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:2001: LightningDeprecationWarning: `Trainer.training_type_plugin` is deprecated in v1.6 and will be removed in v1.8. Use `Trainer.strategy` instead.\n",
            "  rank_zero_deprecation(\n",
            "Average Epoch time: 2979.57 seconds\n",
            "Average Peak memory 34578.41MiB\n",
            "Epoch 0: 100% 1818/1818 [49:39<00:00,  1.64s/it, loss=0.252, v_num=0, train/loss_simple_step=0.124, train/loss_vlb_step=0.00041, train/loss_step=0.124, global_step=1799.0, train/loss_simple_epoch=0.149, train/loss_vlb_epoch=0.00322, train/loss_epoch=0.149]Pruning Checkpoint\n",
            "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
            "Removing optimizer states from checkpoint\n",
            "This is global step 1800.\n",
            "Epoch 1:  10% 180/1818 [04:51<44:08,  1.62s/it, loss=0.315, v_num=0, train/loss_simple_step=0.00433, train/loss_vlb_step=2.49e-5, train/loss_step=0.00433, global_step=1979.0, train/loss_simple_epoch=0.149, train/loss_vlb_epoch=0.00322, train/loss_epoch=0.149]pop from empty list\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:07,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:07,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:07,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:07,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:07,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:00<00:07,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  6.05it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:06,  6.04it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:06,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:06,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:01<00:06,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:05,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:05,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:05,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:05,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:02<00:05,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:02<00:05,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:04,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:04,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:04,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:04,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:03<00:04,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:03<00:04,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:03,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:03,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:04<00:03,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:04<00:03,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:02,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:02,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:05<00:02,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:05<00:02,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:05<00:02,  5.98it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:05<00:02,  6.05it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:01,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:06<00:01,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:06<00:01,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:06<00:01,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:06<00:01,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:00,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:07<00:00,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:07<00:00,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:07<00:00,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:07<00:00,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:07<00:00,  6.21it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  6.18it/s]\n",
            "Data shape for DDIM sampling is (1, 4, 64, 64), eta 1.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:08,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:00<00:08,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:00<00:08,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:00<00:08,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:00<00:08,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:01<00:07,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:01<00:07,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:01<00:07,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:01<00:07,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:01<00:07,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:01<00:06,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:02<00:06,  5.65it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:02<00:06,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:02<00:06,  5.64it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:02<00:06,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:02<00:06,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:03<00:05,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:03<00:05,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:03<00:05,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:04<00:04,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:04<00:04,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:04<00:03,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:05<00:03,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:05<00:03,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:05<00:03,  5.54it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:05<00:03,  5.55it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:05<00:03,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:06<00:02,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:06<00:02,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:06<00:02,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:06<00:02,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:06<00:02,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:06<00:01,  5.57it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:07<00:01,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:07<00:01,  5.58it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:07<00:01,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:07<00:01,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:07<00:01,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:08<00:00,  5.61it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:08<00:00,  5.63it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:08<00:00,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:08<00:00,  5.62it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:08<00:00,  5.62it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:08<00:00,  5.60it/s]\n",
            "Epoch 1:  11% 200/1818 [05:40<45:54,  1.70s/it, loss=0.302, v_num=0, train/loss_simple_step=0.344, train/loss_vlb_step=0.00256, train/loss_step=0.344, global_step=2e+3, train/loss_simple_epoch=0.149, train/loss_vlb_epoch=0.00322, train/loss_epoch=0.149]      Average Epoch time: 340.54 seconds\n",
            "Average Peak memory 23003.46MiB\n",
            "Epoch 1:  11% 200/1818 [05:40<45:54,  1.70s/it, loss=0.302, v_num=0, train/loss_simple_step=0.344, train/loss_vlb_step=0.00256, train/loss_step=0.344, global_step=2e+3, train/loss_simple_epoch=0.138, train/loss_vlb_epoch=0.0014, train/loss_epoch=0.138] Pruning Checkpoint\n",
            "Checkpoint Keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
            "Removing optimizer states from checkpoint\n",
            "This is global step 2000.\n",
            "`Trainer.fit` stopped: `max_steps=2000` reached.\n",
            "Epoch 1:  11% 200/1818 [05:47<46:54,  1.74s/it, loss=0.302, v_num=0, train/loss_simple_step=0.344, train/loss_vlb_step=0.00256, train/loss_step=0.344, global_step=2e+3, train/loss_simple_epoch=0.138, train/loss_vlb_epoch=0.0014, train/loss_epoch=0.138]\n",
            "Training complete. Successfully ran for 2000 steps\n",
            "Copying trained model(s) to trained_models\n",
            "Moving logs/2023-07-06T21-33-34_JoePena-DB-training/ckpts/last.ckpt to trained_models/2023-07-06T22-29-48_JoePena-DB-training_02000_steps_2_training_images_mehseawa_token_woman_class_word.ckpt\n",
            " Download your trained model(s) from the 'trained_models' folder and use in your favorite Stable Diffusion repo!\n"
          ]
        }
      ],
      "source": [
        "#@title 7. Final Setup & Training\n",
        "\n",
        "#@markdown This isn't used for training, just used to name the folders etc\n",
        "project_name = \"JoePena-DB-training\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This is the unique token i.e. you can use a nonsensical word like zwx or your name.\n",
        "token = \"mehseawa\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Match class_word to the category of the regularization images you chose above.\n",
        "class_word = \"woman\" #@param [\"man\", \"person\", \"woman\"] {allow-input: true}\n",
        "\n",
        "# MAX STEPS\n",
        "#@markdown How many steps do you want to train for?\n",
        "max_training_steps = 2000 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown If you are training a person's face, set this to True\n",
        "i_am_training_a_persons_face = True #@param {type:\"boolean\"}\n",
        "flip_p_arg = 0.0 if i_am_training_a_persons_face else 0.5\n",
        "\n",
        "#@markdown Would you like to save a model every X steps? (Example: 250 would output a trained model at 250, 500, 750 steps, etc)\n",
        "save_every_x_steps = 0 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "reg_data_root = \"/content/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
        "\n",
        "!rm -rf training_images/.ipynb_checkpoints\n",
        "!python \"main.py\" \\\n",
        " --project_name \"{project_name}\" \\\n",
        " --debug False \\\n",
        " --max_training_steps {max_training_steps} \\\n",
        " --token \"{token}\" \\\n",
        " --training_model \"model.ckpt\" \\\n",
        " --training_images \"/content/Dreambooth-Stable-Diffusion/training_images\" \\\n",
        " --regularization_images \"{reg_data_root}\" \\\n",
        " --class_word \"{class_word}\" \\\n",
        " --flip_p {flip_p_arg} \\\n",
        " --save_every_x_steps {save_every_x_steps}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mkidEm4evn1J",
        "outputId": "4694672e-c883-41de-ee99-430b0888ccd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title 8. Save model into google drive\n",
        "#@markdown This is often much faster than a manual download.  it will also save you compute units. <br />\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# copy all ckpt files to google drive root dir\n",
        "!cp trained_models/*.ckpt /content/drive/MyDrive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "beb3f7467563465eac17ef6075a82b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a01ab2b4cbf048f080ba1482bfa43e06",
              "IPY_MODEL_63d546ac170948e28540fd817072367f",
              "IPY_MODEL_666b564159044c1daaaed344be553eea"
            ],
            "layout": "IPY_MODEL_8e4cf82a20bc408a9e616cdb087fba4f"
          }
        },
        "a01ab2b4cbf048f080ba1482bfa43e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553d987bcdcb4111b54caa96120f9dec",
            "placeholder": "",
            "style": "IPY_MODEL_fb1a9b57768d4f6baa39dc99038c4d93",
            "value": "Downloading sd_v1-5_vae.ckpt: 100%"
          }
        },
        "63d546ac170948e28540fd817072367f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ffa4201214488c9b9e4fd8890f03ea",
            "max": 4265327726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68e3031674c94b18b59291b3e666687b",
            "value": 4265327726
          }
        },
        "666b564159044c1daaaed344be553eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b812557959d441ca6dda58a08eaa3f1",
            "placeholder": "",
            "style": "IPY_MODEL_1706ffc38ec248d89fbaed5778b634d2",
            "value": " 4.27G/4.27G [00:16&lt;00:00, 262MB/s]"
          }
        },
        "8e4cf82a20bc408a9e616cdb087fba4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553d987bcdcb4111b54caa96120f9dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1a9b57768d4f6baa39dc99038c4d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59ffa4201214488c9b9e4fd8890f03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e3031674c94b18b59291b3e666687b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b812557959d441ca6dda58a08eaa3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1706ffc38ec248d89fbaed5778b634d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}